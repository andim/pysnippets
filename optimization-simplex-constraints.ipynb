{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing a function with probability simplex constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook arose in response to a question on StackOverflow about how to optimize a function with probability simplex constraints in python (see http://stackoverflow.com/questions/32252853/optimization-with-python-scipy-optimize). This is a topic I've thought about a lot for our [paper](http://www.pnas.org/content/112/19/5950.abstract) on optimal immune repertoires so I was interested to see what other people had to say about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "For a given $\\boldsymbol y$ and $\\gamma$ find the $\\boldsymbol x^\\star$ that maximizes the following expression over the probability simplex:\n",
    "\n",
    "$$\\max_{x_i \\geq 0, \\, \\sum_i x_i = 1} \\left[\\sum_i \\left(\\frac{x_i}{y_i}\\right)^\\gamma\\right]^{1/\\gamma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution using scipy.optimize's SLSQP algorithm (user58925)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:2: RuntimeWarning: invalid value encountered in power\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  status: 0\n",
       " success: True\n",
       "    njev: 7\n",
       "    nfev: 38\n",
       "     fun: -265.27701765861417\n",
       "       x: array([ 0.29466743,  0.33480631,  0.37052625])\n",
       " message: 'Optimization terminated successfully.'\n",
       "     jac: array([-265.27723694, -265.27757263, -265.27632904,    0.        ])\n",
       "     nit: 7"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_function(x, y, gamma=0.2):\n",
    "    return -((x/y)**gamma).sum()**(1.0/gamma)\n",
    "\n",
    "cons = ({'type': 'eq', 'fun': lambda x: np.array([sum(x) - 1])})\n",
    "\n",
    "y = np.array([0.5, 0.3, 0.2])\n",
    "initial_x = np.array([0.2, 0.3, 0.5])\n",
    "\n",
    "opt = minimize(objective_function, initial_x, args=(y,), method='SLSQP',\n",
    "               constraints=cons, bounds=[(0, 1)] * len(initial_x))\n",
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works on my machine (the poster on StackOverflow reported issues with this) and actually requires a surprisingly small number of function evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative solution using Nelder-Mead on transformed variables (CT Zhu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trans_x(x):\n",
    "    x1 = x**2/(1.0+x**2)\n",
    "    z  = np.hstack((x1, 1-sum(x1)))\n",
    "    return z\n",
    "\n",
    "def F(x, y, gamma=0.2):\n",
    "    z = trans_x(x)\n",
    "    return -(((z/y)**gamma).sum())**(1./gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:8: RuntimeWarning: invalid value encountered in power\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.29467183,  0.33481782,  0.37051034]),\n",
       "   status: 0\n",
       "    nfev: 73\n",
       " success: True\n",
       "     fun: -265.27701755536299\n",
       "       x: array([ 0.64635885,  0.70946991])\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 39)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = minimize(F, np.array([1., 1.]), args=(np.array(y),),\n",
    "               method='Nelder-Mead')\n",
    "trans_x(opt.x), opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works but needs a slightly higher number of function evaluations for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1., -1.]),\n",
       "   status: 0\n",
       "    nfev: 299\n",
       " success: True\n",
       "     fun: -11.249999999999998\n",
       "       x: array([ -3.10743912e+07,   3.96029532e+10])\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 103)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = minimize(F, np.array([0., 1.]), args=(np.array([0.2, 0.1, 0.8]), 2.0),\n",
    "               method='Nelder-Mead')\n",
    "trans_x(opt.x), opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general though this method can fail, as it does not enforce the non-negativity constraint on the third variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns our the problem is solvable analytically. One can start by writing down the Lagrangian of the (equality constrained) optimization problem:\n",
    "\n",
    "$$L = \\sum_i (x_i/y_i)^\\gamma - \\lambda \\left(\\sum x_i - 1\\right)$$\n",
    "\n",
    "The optimal solution is found by setting the first derivative of this Lagrangian to zero:\n",
    "\n",
    "$$0 = \\partial L / \\partial x_i = \\gamma x_i^{(\\gamma-1)/\\gamma_i} - \\lambda$$\n",
    "$$\\Rightarrow x_i \\propto y_i^{\\gamma/(\\gamma - 1)}$$\n",
    "\n",
    "Using this insight the optimization problem can be solved simply and efficiently:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.29466774,  0.33480719,  0.37052507]), -265.27701765929692)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analytical(y, gamma=0.2):\n",
    "    x = y**(gamma/(gamma-1.0))\n",
    "    x /= np.sum(x)\n",
    "    return x\n",
    "xanalytical = analytical(np.array(y))\n",
    "xanalytical, objective_function(xanalytical, np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution using projected gradient algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem can also be solved using a projected gradient algorithm, but this will be for another time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
